{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This exercise will require you to pull some data from https://data.nasdaq.com/ (formerly Quandl API)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a first step, you will need to register a free account on the https://data.nasdaq.com/ website."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you register, you will be provided with a unique API key, that you should store:\n",
    "\n",
    "*Note*: Use a `.env` file and put your key in there and `python-dotenv` to access it in this notebook. \n",
    "\n",
    "The code below uses a key that was used when generating this project but has since been deleted. Never submit your keys to source control. There is a `.env-example` file in this repository to illusrtate what you need. Copy that to a file called `.env` and use your own api key in that `.env` file. Make sure you also have a `.gitignore` file with a line for `.env` added to it. \n",
    "\n",
    "The standard Python gitignore is [here](https://github.com/github/gitignore/blob/master/Python.gitignore) you can just copy that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KRfk96yoWvruWZ-LjPbo\n"
     ]
    }
   ],
   "source": [
    "# get api key from your .env file\n",
    "import os\n",
    "from dotenv import load_dotenv  # if missing this module, simply run `pip install python-dotenv`\n",
    "\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv('NASDAQ_API_KEY')\n",
    "\n",
    "print(API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nasdaq Data has a large number of data sources, but, unfortunately, most of them require a Premium subscription. Still, there are also a good number of free datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this mini project, we will focus on equities data from the Frankfurt Stock Exhange (FSE), which is available for free. We'll try and analyze the stock prices of a company called Carl Zeiss Meditec, which manufactures tools for eye examinations, as well as medical lasers for laser eye surgery: https://www.zeiss.com/meditec/int/home.html. The company is listed under the stock ticker AFX_X."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find the detailed Nasdaq Data API instructions here: https://docs.data.nasdaq.com/docs/in-depth-usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While there is a dedicated Python package for connecting to the Nasdaq API, we would prefer that you use the *requests* package, which can be easily downloaded using *pip* or *conda*. You can find the documentation for the package here: http://docs.python-requests.org/en/master/ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, apart from the *requests* package, you are encouraged to not use any third party Python packages, such as *pandas*, and instead focus on what's available in the Python Standard Library (the *collections* module might come in handy: https://pymotw.com/3/collections/).\n",
    "Also, since you won't have access to DataFrames, you are encouraged to us Python's native data structures - preferably dictionaries, though some questions can also be answered using lists.\n",
    "You can read more on these data structures here: https://docs.python.org/3/tutorial/datastructures.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep in mind that the JSON responses you will be getting from the API map almost one-to-one to Python's dictionaries. Unfortunately, they can be very nested, so make sure you read up on indexing dictionaries in the documentation provided above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv  # if missing this module, simply run `pip install python-dotenv`\n",
    "import requests \n",
    "import json \n",
    "from datetime import datetime as dt\n",
    "from datetime import date, timedelta\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: API's can change a bit with each version, for this exercise it is reccomended to use the nasdaq api at `https://data.nasdaq.com/api/v3/`. This is the same api as what used to be quandl so `https://www.quandl.com/api/v3/` should work too.\n",
    "\n",
    "Hint: We are looking for the `AFX_X` data on the `datasets/FSE/` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#These are your tasks for this mini project:\n",
    "#1. Collect data from the Qualcomm, for the whole year 2017 (keep in mind that the date format is YYYY-MM-DD).\n",
    "\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv('NASDAQ_API_KEY')\n",
    "\n",
    "url= \"https://data.nasdaq.com/api/v3/datasets/WIKI/FB.json?start_date=2017-01-01&end_date=2017-12-31&collapse=none&transform=none&api_key=\"+API_KEY\n",
    "try:\n",
    "  r = requests.get(url)\n",
    "except:\n",
    "  print(\"An exception occurred\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2017-12-28',\n",
       " 177.95,\n",
       " 178.9367,\n",
       " 177.68,\n",
       " 177.92,\n",
       " 11008996.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 177.95,\n",
       " 178.9367,\n",
       " 177.68,\n",
       " 177.92,\n",
       " 11008996.0]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2. Convert the returned JSON object into a Python dictionary.\n",
    "data_load= json.loads(r.content.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "183.51"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3. Calculate what the highest and lowest opening prices were for the stock in this period.\n",
    "data = data_load['dataset']['data']\n",
    "\n",
    "# highest\n",
    "max_value = max(open_value[1] for open_value in data )\n",
    "max_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116.03"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lowest\n",
    "min_value = min(open_value[1] for open_value in data)\n",
    "min_value   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.97999999999999"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#4. What was the largest change in any one day (based on High and Low price)?\n",
    "larg_diff_h_l = max((open_value[2]-open_value[3]) for open_value in data )\n",
    "larg_diff_h_l\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.6699999999999875"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#5. What was the largest change between any two days (based on Closing Price)?\n",
    "\n",
    "data = data_load['dataset']['data']\n",
    "aux_list = []\n",
    "for c, i in enumerate(data): \n",
    "    \n",
    "    aux_list.append(data[c][4])\n",
    "    change = np.diff(auxList) \n",
    "\n",
    "larg_diff_c_p  = max(change)\n",
    "\n",
    "larg_diff_c_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8234115.169900001"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#6. What was the average daily trading volume during this year?\n",
    "\n",
    "data = data_load['dataset']['data']\n",
    "aux_list = []\n",
    "for c, i in enumerate(data): \n",
    "    \n",
    "    aux_list.append(data[c][5])\n",
    "\n",
    "average = np.mean(auxList) \n",
    "\n",
    "average\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14548954.0"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#7. (Optional) What was the median trading volume during this year. (Note: you may need to implement your own function for calculating the median.)\n",
    "\n",
    "data = aux_list\n",
    "\n",
    "def median(data):\n",
    "    sorted_data = sorted(data)\n",
    "    data_len = len(sorted_data)\n",
    "    middle = (data_len - 1) // 2\n",
    "    if middle % 2:\n",
    "        return sorted_data[middle]\n",
    "    else:\n",
    "        return (sorted_data[middle] + sorted_data[middle + 1]) / 2.0\n",
    "\n",
    "median(aux_list)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4885f37acae9217c235118400878352aafa7b76e66df698a1f601374f86939a7"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
